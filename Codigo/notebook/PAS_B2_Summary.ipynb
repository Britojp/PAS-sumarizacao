{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1º Parte: Receber o arquivo"
      ],
      "metadata": {
        "id": "exSfiyVCrkED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHljSgypJM6k",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Receber o video no colab (Upload)\n",
        "from google.colab import files\n",
        "uploaded = files.upload() # Até ~100MB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Algumas variáveis que afetam o funcionamento do sistema (Obrigatório)\n",
        "\n",
        "### Criação de descrições:\n",
        "# Determina se será feita uma descrição entre sumários vizinhos, visando a melhorar a contextualização entre frames\n",
        "# Aviso: No geral, cada descrição leva, em média, 4 minutos para ser criada. Leve isso em consideração ao habilitar esta variável\n",
        "# Valor recomendando: True\n",
        "criarContexto = True\n",
        "\n",
        "### Extração de áudio\n",
        "# Determina o tamanho máximo do áudio (em segundos) antes que ele seja dividido em seções menores\n",
        "# Valor recomendado: 600 (10 minutos)\n",
        "tamanhoMaximoAudio = 600\n",
        "# Determina o tamanho das seções do áudio (se o áudio durar mais do que tamanhoMaximoAudio)\n",
        "# Valor recomendado: 120 (2 minutos)\n",
        "tamanhoChunkAudio = 120\n",
        "\n",
        "### Extração de frames\n",
        "# Determina o número de frames a serem extraídos a cada segundo\n",
        "# Valor recomendado: 1\n",
        "fpsExtracao = 1\n",
        "# Determina a duração máxima do video antes de reduzir o número máximo de frames (use o valor None para remover esse limite)\n",
        "# i.e. se um video for maior do que duracaoMaximaVideo, então serão extraídos apenas {duracaoMaximaVideo * fpsExtracao} frames, independente da real extensão do vídeo\n",
        "# Valor recomendado: 300 (5 minutos)\n",
        "duracaoMaximaVideo = 300\n",
        "# p.s.: No momento o programa consegue, em média, extrair 3 frames por segundo. Leve isso em consideração, dependendo do tamanho do vídeo e das configurações acima.\n",
        "\n",
        "### Processamento de frames\n",
        "# Determinam, respectivamente, a largura e altura máxima dos frames pós processamento\n",
        "# Valores mais comuns: 1280x720 (720p) e 1920x1080 (Full HD)\n",
        "# Valores recomendados: 1280x720 (720p)\n",
        "larguraMaximaFrame = 1280\n",
        "alturaMaximaFrame = 720"
      ],
      "metadata": {
        "id": "VRedVnVUxqOx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2º Parte: Processar o arquivo (audio e frames)"
      ],
      "metadata": {
        "id": "N83AJ36LrqIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Verificar a duração do video\n",
        "!pip install ffmpeg\n",
        "import ffmpeg\n",
        "import subprocess\n",
        "\n",
        "# Retorna a duração em segundos\n",
        "def verificarDuracaoVideo(videoEntrada):\n",
        "  try:\n",
        "    commando = [\n",
        "      'ffprobe',\n",
        "      '-i', videoEntrada,\n",
        "      '-show_entries', 'format=duration',\n",
        "      '-v', 'quiet',\n",
        "      '-of', 'csv=p=0'\n",
        "    ]\n",
        "    # Executar o comando\n",
        "    resultado = subprocess.run(commando, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    stderr = resultado.stderr.decode('utf-8')\n",
        "    if stderr:\n",
        "      print(f\"Erro do ffprobe: {stderr}\")\n",
        "    # Ler a duração\n",
        "    duracao = float(resultado.stdout.decode('utf-8').strip())\n",
        "    return duracao\n",
        "  except Exception as e:\n",
        "    print(f\"Erro ao converter a duração: {e}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "videoEntrada = None\n",
        "# Encontrar o video\n",
        "import os\n",
        "for arquivo in os.listdir():\n",
        "  if arquivo.endswith(\".mp4\"):\n",
        "    videoEntrada = arquivo\n",
        "    break\n",
        "\n",
        "if videoEntrada:\n",
        "  # Verificar a duração do video\n",
        "  duracaoVideo = verificarDuracaoVideo(videoEntrada)\n",
        "  print(videoEntrada,duracaoVideo)\n",
        "else:\n",
        "  print('Nenhum video encontrado!')"
      ],
      "metadata": {
        "id": "f9gdEK0n3jPl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extrair o audio do video\n",
        "#!pip install ffmpeg-python # redundante\n",
        "\n",
        "import ffmpeg\n",
        "import subprocess\n",
        "\n",
        "def extrair_audio(videoEntrada, localAudioSaida):\n",
        "  try:\n",
        "    subprocess.run([\n",
        "      'ffmpeg', '-i', videoEntrada,\n",
        "      '-vn', '-acodec', 'libmp3lame', '-ab', '192k', localAudioSaida\n",
        "    ], check=False)\n",
        "    print(\"Audio extraido!\")\n",
        "  except Exception as e:\n",
        "    print(f\"Erro: {e}\")\n",
        "\n",
        "videoEntrada = None\n",
        "# Encontrar o video\n",
        "import os\n",
        "for arquivo in os.listdir():\n",
        "  if arquivo.endswith(\".mp4\"):\n",
        "    videoEntrada = arquivo\n",
        "    break\n",
        "\n",
        "if videoEntrada:\n",
        "  localAudioSaida = videoEntrada.replace('.mp4', '.mp3')\n",
        "  extrair_audio(videoEntrada, localAudioSaida)\n",
        "else:\n",
        "  print('Nenhum video encontrado!')"
      ],
      "metadata": {
        "id": "wnDXNgZ8LANg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Se necessário, dividir o audio em partes menores\n",
        "#!pip install ffmpeg-python # redundante\n",
        "import ffmpeg\n",
        "import os\n",
        "\n",
        "def dividirAudio(audioEntrada, localAudioSaida, tamanhoMaximo):\n",
        "  # Se não existir -> criar a pasta\n",
        "  if not os.path.exists(localAudioSaida):\n",
        "    os.makedirs(localAudioSaida)\n",
        "  # Tentar dividir o audio\n",
        "  try:\n",
        "    ffmpeg.input(audioEntrada).output(f\"{localAudioSaida}/chunk%03d.mp3\", f='segment', segment_time=tamanhoMaximo).run()\n",
        "    print(\"Audio dividido!\")\n",
        "  except ffmpeg.Error as e:\n",
        "    print(f\"Erro: {e.stderr.decode()}\")\n",
        "\n",
        "# Encontrar o audio\n",
        "audioEntrada = None\n",
        "for arquivo in os.listdir():\n",
        "  if arquivo.endswith(\".mp3\"):\n",
        "    audioEntrada = arquivo\n",
        "    break\n",
        "\n",
        "if audioEntrada and (duracaoVideo > tamanhoMaximoAudio): # Padrão: tamanhoMaximoAudio de 10*60\n",
        "  print('Divisões do audio criadas!')\n",
        "  dividirAudio(audioEntrada,'./Audio/', tamanhoChunkAudio) # Padrão: tamanhoChunkAudio de 2*60\n",
        "else:\n",
        "  print('Nenhuma divisão criada!')"
      ],
      "metadata": {
        "id": "wATlD6KBqwx4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extrair os frames do video\n",
        "# extrai 2~4 frames por segundo\n",
        "!pip install opencv-python\n",
        "import cv2\n",
        "import time\n",
        "import os\n",
        "\n",
        "def extrairFrames(videoEntrada, localFramesSaida):\n",
        "  try:\n",
        "    # Se não existir -> criar a pasta\n",
        "    if not os.path.exists(localFramesSaida):\n",
        "      os.makedirs(localFramesSaida)\n",
        "\n",
        "    start_time = time.time() # Para o cronometro\n",
        "\n",
        "    cap = cv2.VideoCapture(videoEntrada)\n",
        "    frame_count = 0\n",
        "    frame_counter = 0\n",
        "    # Determinar intervalo da captura\n",
        "    #fpsExtracao = 4\n",
        "    #duracaoMaximaVideo = 5*60\n",
        "    intervaloExtracao = 1.0/fpsExtracao\n",
        "    if duracaoMaximaVideo:\n",
        "      if duracaoVideo > duracaoMaximaVideo:\n",
        "        intervaloExtracao = duracaoVideo/(fpsExtracao*duracaoMaximaVideo)\n",
        "    # Video em si\n",
        "    while cap.isOpened():\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "          break\n",
        "\n",
        "      current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0  # Get timestamp in seconds\n",
        "\n",
        "      # Salvar o frame a cada {intervaloExtracao}\n",
        "      if current_time >= frame_count * intervaloExtracao:\n",
        "          frame_filename = os.path.join(localFramesSaida, f\"frame_{frame_counter:04}_time_{current_time:.2f}.png\")\n",
        "          cv2.imwrite(frame_filename, frame)\n",
        "          frame_counter += 1\n",
        "          frame_count += 1\n",
        "\n",
        "      # Break para quando o video ter acabado\n",
        "      if current_time > cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0:\n",
        "          break\n",
        "\n",
        "    cap.release()\n",
        "    end_time = time.time() # Parar o cronometro\n",
        "    print('Frames extraidos')\n",
        "    print(f\"Tempo de execução: {end_time - start_time: .1f} segundos\")\n",
        "    print(f\"{(frame_counter+1)/(end_time-start_time): .2f} frames por segundo\")\n",audioEntrada
        "  except Exception as e:\n",
        "    print(f\"Erro: {e}\")\n",
        "\n",
        "# Encontrar o video\n",
        "videoEntrada = None\n",
        "for arquivo in os.listdir():\n",
        "  if arquivo.endswith(\".mp4\"):\n",
        "    videoEntrada = arquivo\n",
        "    break\n",
        "\n",
        "if videoEntrada:\n",
        "  print(f\"Previsão simplificada: {int((duracaoVideo/3)/3600)}h {int(((duracaoVideo/3)/60)%60)}min {(duracaoVideo/3)%60:.1f}s\")\n",
        "  extrairFrames(videoEntrada, './Frames/Original/')\n",
        "else:\n",
        "  print('Nenhum video encontrado!')"
      ],
      "metadata": {
        "id": "pqWAdTNcAiK7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Processar os frames (Recomendado)\n",
        "!pip install Pillow\n",
        "from PIL import Image\n",
        "\n",
        "def processarFrames(localFrames):\n",
        "  try:\n",
        "    # Tentar processar os frames\n",
        "    flagFramesGrandes = False\n",
        "    previsaoAvisada = False\n",
        "    for arquivo in os.listdir(localFrames):\n",
        "      if arquivo.endswith('.png'):\n",
        "        # Imagem recebida\n",
        "        with Image.open(os.path.join(localFrames,arquivo)) as img:\n",
        "          # Verificando tamanho da imagem\n",
        "          width, height = img.size\n",
        "          if width > larguraMaximaFrame or height > alturaMaximaFrame: # Reduzir tamanho\n",
        "            # Se não existir -> criar a pasta\n",
        "            if not os.path.exists('./Frames/Processados/'):\n",
        "                os.makedirs('./Frames/Processados/')\n",
        "            # Previsão de duração\n",
        "            flagFramesGrandes = True # flag para a previsao\n",
        "            if flagFramesGrandes and not previsaoAvisada:\n",
        "              previsaoAvisada = True # Impedir outro print\n",
        "              print(f\"Previsao simplificada: {int((len(os.listdir('./Frames/Original/'))/3)/3600)}h {int(((len(os.listdir('./Frames/Original/'))/3)/60)%60)}min {(len(os.listdir('./Frames/Original/'))/3)%60:.1f}s\")\n",
        "            # Seguir proporção para evitar distorção\n",
        "            proporcao = width/height\n",
        "            if proporcao > 1: # Paisagem\n",
        "              img = img.resize((larguraMaximaFrame, int(larguraMaximaFrame/proporcao)), Image.Resampling.LANCZOS)\n",
        "            else: # Retrato\n",
        "              img = img.resize((int(alturaMaximaFrame*proporcao), alturaMaximaFrame), Image.Resampling.LANCZOS)\n",
        "\n",
        "            # Salvar imagem na nova pasta\n",
        "            img.save(os.path.join('./Frames/Processados/', arquivo))\n",
        "    print('Frames processados')\n",
        "  except Exception as e:\n",
        "    print(f\"Erro: {e}\")\n",
        "\n",
        "# Tentar processar os frames\n",
        "import os\n",
        "if os.path.exists('./Frames/Original/'):\n",
        "  processarFrames('./Frames/Original/')\n",
        "else:\n",
        "  print('Nenhum frame encontrado!')"
      ],
      "metadata": {
        "id": "juGFtwclQjR9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title imprime os arquivos criados (opcional)\n",
        "import os\n",
        "print(os.listdir())\n",
        "# audio\n",
        "if os.path.exists('./Audio/'):\n",
        "  print(sorted(os.listdir('./Audio/')))\n",
        "  print(len(os.listdir('./Audio/')),end='\\n------\\n')\n",
        "# frames originais\n",
        "if os.path.exists('./Frames/Original/'):\n",
        "  print(sorted(os.listdir('./Frames/Original/')))\n",
        "  print(len(os.listdir('./Frames/Original/')),end='\\n------\\n')\n",
        "# frames processados\n",
        "if os.path.exists('./Frames/Processados/'):\n",
        "  print(sorted(os.listdir('./Frames/Processados/')))\n",
        "  print(len(os.listdir('./Frames/Processados/')),end='\\n------\\n')"
      ],
      "metadata": {
        "id": "Vj3vDVL7_goR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3º Parte: Criar descrição e transcrição dos frames e áudio, respectivamente"
      ],
      "metadata": {
        "id": "izqWWCP-ryEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transcrição do audio (Whisper)\n",
        "!pip install openai-whisper\n",
        "import whisper\n",
        "\n",
        "def transcreverAudio(audioEntrada):\n",
        "  try:\n",
        "    # Tentar transcrever o audio\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audioEntrada, language='pt')\n",
        "    print(\"Audio transcrito!\")\n",
        "    return result[\"text\"]\n",
        "  except Exception as e:\n",
        "    print(f\"Erro: {e}\")\n",
        "    return None\n",
        "\n",
        "transcricaoAudio = None\n",
        "# Tentar usar os audios divididos\n",
        "if os.path.exists('./Audio/'):\n",
        "  transcricaoAudio = \"\"\n",
        "  for arquivo in sorted(os.listdir('./Audio/')):\n",
        "    if arquivo.endswith(\".mp3\"):\n",
        "      transcricaoAudio += transcreverAudio(arquivo)\n",
        "# Se não usar o original\n",
        "else:\n",
        "  for arquivo in os.listdir():\n",
        "    if arquivo.endswith(\".mp3\"):\n",
        "      transcricaoAudio = transcreverAudio(arquivo)\n",
        "      break\n",
        "    else:\n",
        "      print('Nenhum audio encontrado!')"
      ],
      "metadata": {
        "id": "7HdN2KQKWk1S",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Descrição dos frames\n",
        "## Média de 5~7 segundos por frame\n",
        "!pip install torch transformers pillow\n",
        "\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # Tenta configurar o modelo\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    # Descrição de 1 frame\n",
        "    def descrever_frame(caminho_imagem):\n",
        "        image = Image.open(caminho_imagem).convert(\"RGB\")\n",
        "\n",
        "        # Processa a imagem com o processador BLIP, retornando os tensores necessários para o modelo\n",
        "        inputs = processor(image, return_tensors=\"pt\")\n",
        "\n",
        "        # Gera a descrição da imagem a partir do modelo BLIP (max_length=100 significa que a descrição terá no máximo 100 tokens)\n",
        "        output = model.generate(**inputs, max_length=100)\n",
        "\n",
        "        # Decodifica a saída do modelo e converte para uma string legível\n",
        "        descricao = processor.decode(output[0], skip_special_tokens=True)\n",
        "        return descricao\n",
        "\n",
        "    # Lista com a descrição dos frames\n",
        "    def descreverFramesVideo(localFrames):\n",
        "      import time\n",
        "      listaDescricaoFrames = [] # List para armazenar as descrições\n",
        "      # Carregar vários frames\n",
        "      start_time = time.time()\n",
        "      counter = 0\n",
        "      for frame in sorted(os.listdir(localFrames)):\n",
        "        if frame.endswith((\".jpg\", \".png\")):\n",
        "          # Mandar mais feedback para o usuário\n",
        "          counter += 1\n",
        "          if counter % 10 == 0:\n",
        "            print(f\"{counter} frames processados em {int((time.time()-start_time)/60)}min {(time.time()-start_time)%60: .1f}s\")\n",
        "\n",
        "          caminho = os.path.join(localFrames, frame)\n",
        "          descricao = descrever_frame(caminho)\n",
        "          # Dict para também armazenar o frame (por consequencia o timestamp)\n",
        "          infoFrame = {\n",
        "              'frame': frame,\n",
        "              'descricao': descricao,\n",
        "          }\n",
        "          listaDescricaoFrames.append(infoFrame)\n",
        "      end_time = time.time()\n",
        "      print('Descrição de frames criada!')\n",
        "      print(f\"{(end_time-start_time)/len(listaDescricaoFrames): .2f} segundos por frame\")\n",
        "      return listaDescricaoFrames\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erro: {e}\")\n",
        "\n",
        "pastaFrames = \"./Frames/Processados/\" # Tentar usar os frames já processados\n",
        "# Usar original se não foi necessário processar\n",
        "if not os.path.exists(pastaFrames): # Frames processados não existem -> usar os originais\n",
        "  pastaFrames = './Frames/Original/'\n",
        "\n",
        "if os.path.exists(pastaFrames):\n",
        "  listDescricoesFrames = None # Salvar para caso de erro\n",
        "  listDescricoesFrames = descreverFramesVideo(pastaFrames)\n",
        "else:\n",
        "  print('Nenhum video encontrado!')"
      ],
      "metadata": {
        "id": "dSR9dBNrWpMj",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4º Parte: Criação do sumário"
      ],
      "metadata": {
        "id": "nfW5ESbzd9iZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1: Confirgurar o ollama"
      ],
      "metadata": {
        "id": "mLa2G3wAD5Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instalando o ollama\n",
        "!pip install ollama\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "30C8FuLkPd1y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Verificar o funcionamento do llama (Recomendado)\n",
        "!ps aux | grep ollama # Verificar processos rodando\n",
        "!nohup ollama serve > ollama.log 2>&1 & ## Reset ollama\n",
        "# por alguma razão resetar o llama aqui reduz a chance dele ficar preso no !ollama serve"
      ],
      "metadata": {
        "id": "BOFEkVo4JNld",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Iniciar o servidor para o ollama\n",
        "%env OLLAMA_DEBUG=1\n",
        "%env OLLAMA_NO_GPU=1\n",
        "\n",
        "!ollama serve"
      ],
      "metadata": {
        "id": "ACYOMWr9EC-K",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Baixar o modelo\n",
        "!ollama pull mistral # Mais barato que LLaMA 3:8B"
      ],
      "metadata": {
        "id": "uUhdpAVhD9oK",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Verifica no servidor quais modelos foram instalados (Opcional)\n",
        "!curl http://127.0.0.1:11434/api/tags"
      ],
      "metadata": {
        "id": "cuC1MnMALVl7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2: Criando os sumários usando ollama"
      ],
      "metadata": {
        "id": "zIklV_a8WFJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tentativa de criação de contexto (criar uma descrição entre dois frames vizinhos)\n",
        "# Baseado em https://github.com/GoloMarcos/LLM4BrazilianFakeNews/blob/main/Evaluation.ipynb\n",
        "# 150~280 segundos por par\n",
        "# Limite de 90 minutos de execução por causa do plano gratuito\n",
        "import ollama\n",
        "import time\n",
        "\n",
        "# Fazer a analise entre a descrição de dois frames\n",
        "def analisaVizinhosLlama(model, desc1, desc2):\n",
        "  # Variaveis para refencia na prompt\n",
        "  descricao1 = desc1['descricao']\n",
        "  frame1_time = desc1['frame'].split('_time_')[1].split('.')[0]\n",
        "  descricao2 = desc2['descricao']\n",
        "  frame2_time = desc2['frame'].split('_time_')[1].split('.')[0]\n",
        "  # prompt\n",
        "  response = ollama.chat(model=model, messages=[{\n",
        "    'role': 'user',\n",
        "    'content': f'Considere as duas descrições em inglês a seguir e resuma-as em pt-br, contextualizando elas em conjunto. Explique como as duas se relacionam/diferenciam e o que elas podem significar em conjunto\\nDescrição 1: {descricao1} instante {frame1_time}\\nDescrição 2: {descricao2} instante {frame2_time}\\nSeu resumo deve integrar as duas descrições e proporcionar uma visão clara e coerente do contexto geral.'\n",
        "  },\n",
        "  ])\n",
        "  return response['message']['content']\n",
        "\n",
        "# Criar a lista com as novas descrições\n",
        "model = 'mistral'\n",
        "def descricaoFramesVizinhosLlama(listDescricoesRecebida, indexInicio, indexFim, start_time = time.time()):\n",
        "  listDescricoesVizinhos = []\n",
        "  for i in range(indexInicio, min(indexFim, (len(listDescricoesRecebida)-1))): # Percorrer até o indexFim ou o penultimo item da lista\n",
        "    resposta = analisaVizinhosLlama(model, listDescricoesFrames[i], listDescricoesFrames[i+1]) # enviar par de descricoes\n",
        "    # se recebido -> adicionar na lista\n",
        "    if resposta:\n",
        "      # Armazenar as informações dos frames e a nova descrição\n",
        "      dictResposta = {\n",
        "          'frame1': listDescricoesFrames[i]['frame'],\n",
        "          'frame2': listDescricoesFrames[i+1]['frame'],\n",
        "          'descricao': resposta,\n",
        "      }\n",
        "      listDescricoesVizinhos.append(dictResposta)\n",
        "    # Um pouco mais de responsividade devido o tempo de execução\n",
        "    print(f'{i}/{len(listDescricoesRecebida)-1} em {int((time.time()-start_time)/3600)}h {int((time.time()-start_time)/60)%60}min {(time.time()-start_time)%60:.1f}s') # Cronometro\n",
        "  return listDescricoesVizinhos\n",
        "\n",
        "# Rodar as funções para permitir a chamada em outra célula\n",
        "if listDescricoesFrames and criarContexto:\n",
        "  print(\"Criando resultado inicial\")\n",
        "  tempoPrevisao = time.time()\n",
        "  descricaoFramesVizinhosLlama(listDescricoesFrames, 0, 1)\n",
        "  tempoPrevisao = time.time() - tempoPrevisao\n",
        "else:\n",
        "    print('Nenhuma descrição encontrada!')"
      ],
      "metadata": {
        "id": "jl4cYAjejFKf",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Criar a lista de contexto com as restrições do colab gratuito\n",
        "##### Primeiro rodar a celula acima\n",
        "import time\n",
        "def criarSumarioVizinhosLLama(listaDescricoesOriginais):\n",
        "  step = int((80*60)/tempoPrevisao) # reduzindo cada chunk para periodos de 80 minutos por segurança\n",
        "  teto = 0\n",
        "  resultadoCompleto = []\n",
        "  start_timeGeral = time.time()\n",
        "  while(teto < len(listaDescricoesOriginais)):\n",
        "    teto += step\n",
        "    resultadoParcial = descricaoFramesVizinhosLlama(listaDescricoesOriginais, (teto-step), teto, start_timeGeral)\n",
        "    if resultadoParcial:\n",
        "      resultadoCompleto += resultadoParcial\n",
        "  return resultadoCompleto\n",
        "\n",
        "if listDescricoesFrames and criarContexto:\n",
        "  print(f'Previsao simplificada: {int((tempoPrevisao*(len(listDescricoesFrames)-1))/3600)}h {int((tempoPrevisao*(len(listDescricoesFrames)-1))/60)%60}min {(tempoPrevisao*(len(listDescricoesFrames)-1))%60:.1f}s')\n",
        "  print(f'Tamanho de cada step: {int((80*60)/tempoPrevisao)}')\n",
        "  print(f'Numero de chunks: {int(len(listDescricoesFrames)/((80*60)/tempoPrevisao))}')\n",
        "  novoResultadoContexto = criarSumarioVizinhosLLama(listDescricoesFrames)\n",
        "else:\n",
        "    print('Nenhuma descrição encontrada!')"
      ],
      "metadata": {
        "id": "u4zAujQnt2pc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sumarizar a parte visual do video\n",
        "# Baseado em https://github.com/GoloMarcos/LLM4BrazilianFakeNews/blob/main/Evaluation.ipynb\n",
        "#!pip install ollama\n",
        "import ollama\n",
        "\n",
        "# Fazer a analise entre a descrição de dois frames\n",
        "def analisaDescricoesFramesLlama(model, descricoes):\n",
        "  # Criação do prompt para todas as descrições\n",
        "  prompt = \"Considere as seguintes descrições, possivelmente em inglês, e resuma-as em português (pt-br), contextualizando todas em conjunto. Explique como elas se relacionam/diferenciam e o que elas podem significar em conjunto:\\n\"\n",
        "\n",
        "  # Adiconar cada descrição e sua respectiva timestamp\n",
        "  for i, desc in enumerate(descricoes):\n",
        "    if 'frame' in desc:\n",
        "      prompt += f\"\\nDescrição {i + 1}: {desc['descricao']} instante {desc['frame'].split('_time_')[1].split('.')[0]}\"\n",
        "    else:\n",
        "      prompt += f\"\\nDescrição {i + 1}: {desc['descricao']} instante {desc['frame1'].split('_time_')[1].split('.')[0]} até instante {desc['frame2'].split('_time_')[1].split('.')[0]}\"\n",
        "\n",
        "  prompt += \"\\nSeu resumo deve integrar todas as descrições e fornecer uma visão clara e coerente do contexto geral.\"\n",
        "\n",
        "  response = ollama.chat(model=model, messages=[{\n",
        "    'role': 'user',\n",
        "    'content': prompt,\n",
        "  },\n",
        "  ])\n",
        "  return response['message']['content']\n",
        "\n",
        "# Criar a lista com as novas descrições\n",
        "model = 'mistral'\n",
        "def analiseFramesLlama(listDescricoes):\n",
        "  if listDescricoes:\n",
        "    # Chama a função de análise para todas as descrições de uma vez\n",
        "    resposta = analisaDescricoesFramesLlama(model, listDescricoes)\n",
        "    if resposta:\n",
        "      print('Descrição final dos frames criada!')\n",
        "    return resposta # Pode ser vazia\n",
        "  else:\n",
        "      return None\n",
        "\n",
        "# Tentar descricao com contexto\n",
        "try:\n",
        "  if 'novoResultadoContexto' in locals() or 'novoResultadoContexto' in globals():\n",
        "    if novoResultadoContexto:\n",
        "      print(\"Sumários de vizinhos encontrados!\")\n",
        "      print(f\"Previsão simplificada: {int(((len(novoResultadoContexto))*11.0)/3600)}h {int(((len(novoResultadoContexto))*11.0)/60)%60}min {((len(novoResultadoContexto))*11.0)%60:.1f}s\")\n",
        "      sumarioParteVisual = analiseFramesLlama(novoResultadoContexto)\n",
        "  else:\n",
        "    raise NameError()\n",
        "except NameError: # Não tem -> tentar original\n",
        "  if 'listDescricoesFrames' in locals() or 'listDescricoesFrames' in globals():\n",
        "    if listDescricoesFrames:\n",
        "      print(\"Sumários de frames encontrados!\")\n",
        "      print(f\"Previsão simplificada: {int(((len(listDescricoesFrames))*9.1)/3600)}h {int(((len(listDescricoesFrames))*9.1)/60)%60}min {((len(listDescricoesFrames))*9.1)%60:.1f}s\")\n",
        "      sumarioParteVisual = analiseFramesLlama(listDescricoesFrames)\n",
        "  else:\n",
        "    raise NameError()\n",
        "except NameError:\n",
        "  print('Nenhuma descrição encontrada!')"
      ],
      "metadata": {
        "id": "a6IU534zsKMb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Criação do sumário final, sumarizar com a transcrição do audio e descrição dos frames\n",
        "# Baseado em https://github.com/GoloMarcos/LLM4BrazilianFakeNews/blob/main/Evaluation.ipynb\n",
        "#pip install ollama\n",
        "import ollama\n",
        "\n",
        "# Fazer a analise entre a descrição de dois frames\n",
        "def analiseFinal(model, descricaoVisual, descricaoAudio):\n",
        "  # Criação do prompt para todas as descrições\n",
        "  prompt = \"Considere as seguintes descrições do visual e audio de um video e resuma-as, contextualizando todas em conjunto. Explique como elas se relacionam/diferenciam e o que elas podem significar em conjunto, destacando eventos importantes:\\n\"\n",
        "  prompt += f'Parte visual do video: {descricaoVisual}\\n'\n",
        "  prompt += f'Audio do video: {descricaoAudio}\\n'\n",
        "  prompt += \"\\nSeu resumo deve integrar todas as descrições e fornecer uma visão clara e coerente do contexto geral.\"\n",
        "\n",
        "  response = ollama.chat(model=model, messages=[{\n",
        "    'role': 'user',\n",
        "    'content': prompt,\n",
        "  },\n",
        "  ])\n",
        "  return response['message']['content']\n",
        "\n",
        "\n",
        "model = 'mistral'\n",
        "if sumarioParteVisual and transcricaoAudio:\n",
        "  print(\"Criando sumário final\")\n",
        "  print(\"Previsão simplificada: 15~25min\")\n",
        "  sumarioFinal = analiseFinal(model, sumarioParteVisual, transcricaoAudio)\n",
        "  print('Descrição final criada!')\n",
        "else:\n",
        "  sumarioFinal = None"
      ],
      "metadata": {
        "id": "r2gDpgKfxcGw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Exibindo o sumário criado\n",
        "print(sumarioFinal)"
      ],
      "metadata": {
        "id": "nLUf8-2-ZHMI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possíveis APIs para a 4ª parte: uso de BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), Hugging Face Models, Deepseek"
      ],
      "metadata": {
        "id": "TgXH2IfWxjS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5º Parte: Análise do sumário com dados do video (Título, thumbnail, tags)"
      ],
      "metadata": {
        "id": "tsghD7AOeB1p"
      }
    }
  ]
}
